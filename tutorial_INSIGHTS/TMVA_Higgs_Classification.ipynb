{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://oproject.org/tiki-download_file.php?fileId=8&display&x=450&y=128\">\n",
    "<img src=\"http://files.oproject.org/tmvalogo.png\" height=\"50%\" width=\"50%\">\n",
    "\n",
    "# TMVA Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods\n",
    "whose performance you'd like to investigate. \n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    " - The first argument is the base of the name of all the output\n",
    "weightfiles in the directory weight/ that will be created with the \n",
    "method parameters \n",
    "\n",
    " - The second argument is the output file for the training results\n",
    "  \n",
    " - The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMVA::Tools::Instance();\n",
    "\n",
    "\n",
    "auto outputFile = TFile::Open(\"Higgs_ClassificationOutput.root\", \"RECREATE\");\n",
    "\n",
    "TMVA::Factory factory(\"TMVA_Higgs_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" ); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset(s)\n",
    "\n",
    "Define input data file and signal and background trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :sig_tree  : Signal Tree                                            *\n",
      "*Entries :    10000 : Total =         1141446 bytes  File  Size =    1000730 *\n",
      "*        :          : Tree compression factor =   1.13                       *\n",
      "******************************************************************************\n",
      "*Br    0 :lepton_pT : lepton_pT/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      30836 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br    1 :lepton_eta : lepton_eta/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40768 bytes  File Size  =      29658 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br    2 :lepton_phi : lepton_phi/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40768 bytes  File Size  =      30676 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br    3 :missing_energy_magnitude : missing_energy_magnitude/F              *\n",
      "*Entries :    10000 : Total  Size=      40866 bytes  File Size  =      31999 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    4 :missing_energy_phi : missing_energy_phi/F                          *\n",
      "*Entries :    10000 : Total  Size=      40824 bytes  File Size  =      31997 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    5 :jet1_pt   : jet1_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40747 bytes  File Size  =      31160 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.03     *\n",
      "*............................................................................*\n",
      "*Br    6 :jet1_eta  : jet1_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      29438 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.09     *\n",
      "*............................................................................*\n",
      "*Br    7 :jet1_phi  : jet1_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      30354 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    8 :jet1_btag : jet1_btag/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      13830 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   2.31     *\n",
      "*............................................................................*\n",
      "*Br    9 :jet2_pt   : jet2_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40747 bytes  File Size  =      30906 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br   10 :jet2_eta  : jet2_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      29501 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br   11 :jet2_phi  : jet2_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      30439 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br   12 :jet2_btag : jet2_btag/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      13678 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   2.34     *\n",
      "*............................................................................*\n",
      "*Br   13 :jet3_pt   : jet3_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40747 bytes  File Size  =      30367 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br   14 :jet3_eta  : jet3_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      29687 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br   15 :jet3_phi  : jet3_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      30460 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br   16 :jet3_btag : jet3_btag/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      12542 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   2.55     *\n",
      "*............................................................................*\n",
      "*Br   17 :jet4_pt   : jet4_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40747 bytes  File Size  =      29694 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br   18 :jet4_eta  : jet4_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      29857 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.07     *\n",
      "*............................................................................*\n",
      "*Br   19 :jet4_phi  : jet4_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      30412 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br   20 :jet4_btag : jet4_btag/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      11691 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   2.74     *\n",
      "*............................................................................*\n",
      "*Br   21 :m_jj      : m_jj/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40726 bytes  File Size  =      31999 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   22 :m_jjj     : m_jjj/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40733 bytes  File Size  =      31996 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   23 :m_lv      : m_lv/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40726 bytes  File Size  =      31707 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.01     *\n",
      "*............................................................................*\n",
      "*Br   24 :m_jlv     : m_jlv/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40733 bytes  File Size  =      31996 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   25 :m_bb      : m_bb/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40726 bytes  File Size  =      31999 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   26 :m_wbb     : m_wbb/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40733 bytes  File Size  =      31996 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   27 :m_wwbb    : m_wwbb/F                                               *\n",
      "*Entries :    10000 : Total  Size=      40740 bytes  File Size  =      31997 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "TString inputFileName = \"Higgs_data.root\";\n",
    "\n",
    "//TString inputFileName = \"tmva_class_example.root\";\n",
    "\n",
    "auto inputFile = TFile::Open( inputFileName );\n",
    "\n",
    "// --- Register the training and test trees\n",
    "\n",
    "TTree *signalTree     = (TTree*)inputFile->Get(\"sig_tree\");\n",
    "TTree *backgroundTree = (TTree*)inputFile->Get(\"bkg_tree\");\n",
    "\n",
    "signalTree->Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input variables \n",
    "\n",
    "Define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMVA::DataLoader * loader = new TMVA::DataLoader(\"dataset\");\n",
    "\n",
    "loader->AddVariable(\"m_jj\");\n",
    "loader->AddVariable(\"m_jjj\");\n",
    "loader->AddVariable(\"m_lv\");\n",
    "loader->AddVariable(\"m_jlv\");\n",
    "loader->AddVariable(\"m_bb\");\n",
    "loader->AddVariable(\"m_wbb\");\n",
    "loader->AddVariable(\"m_wwbb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set now the input data trees in the TMVA DataLoader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sig_tree of type Signal with 10000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg_tree of type Background with 10000 events\n"
     ]
    }
   ],
   "source": [
    "// global event weights per tree (see below for setting event-wise weights)\n",
    "Double_t signalWeight     = 1.0;\n",
    "Double_t backgroundWeight = 1.0;\n",
    "   \n",
    "// You can add an arbitrary number of signal or background trees\n",
    "loader->AddSignalTree    ( signalTree,     signalWeight     );\n",
    "loader->AddBackgroundTree( backgroundTree, backgroundWeight );\n",
    "\n",
    "\n",
    "// Set individual event weights (the variables must exist in the original TTree)\n",
    "//    for signal    : factory->SetSignalWeightExpression    (\"weight1*weight2\");\n",
    "//    for background: factory->SetBackgroundWeightExpression(\"weight1*weight2\");\n",
    "//loader->SetBackgroundWeightExpression( \"weight\" );\n",
    "\n",
    "// Apply additional cuts on the signal and background samples (can be different)\n",
    "TCut mycuts = \"\"; // for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "TCut mycutb = \"\"; // for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "// Tell the factory how to use the training and testing events\n",
    "//\n",
    "// If no numbers of events are given, half of the events in the tree are used \n",
    "// for training, and the other half for testing:\n",
    "//    loader->PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" );\n",
    "// To also specify the number of testing events, use:\n",
    "\n",
    "loader->PrepareTrainingAndTestTree( mycuts, mycutb,\n",
    "                                    \"nTrain_Signal=7000:nTrain_Background=7000:SplitMode=Random:NormMode=NumEvents:!V\" );\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Methods\n",
    "\n",
    "Here we book the TMVA methods. We book a Likelihood based on KDE, a Fischer discriminant and a BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mLikelihoodKDE\u001b[0m\n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mFisher\u001b[0m\n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 7000\n",
      "                         : Signal     -- testing events             : 3000\n",
      "                         : Signal     -- training and testing events: 10000\n",
      "                         : Background -- training events            : 7000\n",
      "                         : Background -- testing events             : 3000\n",
      "                         : Background -- training and testing events: 10000\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ----------------------------------------------------------------\n",
      "                         :             m_jj   m_jjj    m_lv   m_jlv    m_bb   m_wbb  m_wwbb\n",
      "                         :    m_jj:  +1.000  +0.803  +0.010  +0.120  +0.033  +0.539  +0.533\n",
      "                         :   m_jjj:  +0.803  +1.000  +0.010  +0.112  +0.156  +0.686  +0.658\n",
      "                         :    m_lv:  +0.010  +0.010  +1.000  +0.098  -0.056  +0.004  +0.021\n",
      "                         :   m_jlv:  +0.120  +0.112  +0.098  +1.000  +0.311  +0.558  +0.576\n",
      "                         :    m_bb:  +0.033  +0.156  -0.056  +0.311  +1.000  +0.471  +0.332\n",
      "                         :   m_wbb:  +0.539  +0.686  +0.004  +0.558  +0.471  +1.000  +0.901\n",
      "                         :  m_wwbb:  +0.533  +0.658  +0.021  +0.576  +0.332  +0.901  +1.000\n",
      "                         : ----------------------------------------------------------------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ----------------------------------------------------------------\n",
      "                         :             m_jj   m_jjj    m_lv   m_jlv    m_bb   m_wbb  m_wwbb\n",
      "                         :    m_jj:  +1.000  +0.797  +0.012  +0.169  +0.044  +0.405  +0.426\n",
      "                         :   m_jjj:  +0.797  +1.000  +0.010  +0.198  +0.177  +0.551  +0.533\n",
      "                         :    m_lv:  +0.012  +0.010  +1.000  +0.129  +0.017  +0.031  +0.041\n",
      "                         :   m_jlv:  +0.169  +0.198  +0.129  +1.000  +0.268  +0.604  +0.570\n",
      "                         :    m_bb:  +0.044  +0.177  +0.017  +0.268  +1.000  +0.616  +0.439\n",
      "                         :   m_wbb:  +0.405  +0.551  +0.031  +0.604  +0.616  +1.000  +0.883\n",
      "                         :  m_wwbb:  +0.426  +0.533  +0.041  +0.570  +0.439  +0.883  +1.000\n",
      "                         : ----------------------------------------------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mMLP\u001b[0m\n",
      "                         : \n",
      "MLP                      : [dataset] : Create Transformation \"N\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n",
      "MLP                      : Building Network. \n",
      "                         : Initializing weights\n"
     ]
    }
   ],
   "source": [
    "// Likelihood (\"naive Bayes estimator\")\n",
    "//factory.BookMethod(loader, TMVA::Types::kLikelihood, \"Likelihood\",\n",
    "//                           \"H:!V:TransformOutput:PDFInterpol=Spline2:NSmoothSig[0]=20:NSmoothBkg[0]=20:NSmoothBkg[1]=10:NSmooth=1:NAvEvtPerBin=50\" );\n",
    "\n",
    "// Use a kernel density estimator to approximate the PDFs\n",
    "factory.BookMethod(loader, TMVA::Types::kLikelihood, \"LikelihoodKDE\",\n",
    "                           \"!H:!V:!TransformOutput:PDFInterpol=KDE:KDEtype=Gauss:KDEiter=Adaptive:KDEFineFactor=0.3:KDEborder=None:NAvEvtPerBin=50\" ); \n",
    "\n",
    "\n",
    "// Fisher discriminant (same as LD)\n",
    "factory.BookMethod(loader, TMVA::Types::kFisher, \"Fisher\", \"H:!V:Fisher:VarTransform=None:CreateMVAPdfs:PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=50:NsmoothMVAPdf=10\" );\n",
    "\n",
    "\n",
    "//Boosted Decision Trees\n",
    "factory.BookMethod(loader,TMVA::Types::kBDT, \"BDT\",\n",
    "                   \"!V:NTrees=200:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" );\n",
    "\n",
    "//Multi-Layer Perceptron (Neural Network)\n",
    "factory.BookMethod(loader, TMVA::Types::kMLP, \"MLP\",\n",
    "                   \"!H:!V:NeuronType=tanh:VarTransform=N:NCycles=100:HiddenLayers=N+5:TestRate=5:!UseRegulator\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booking Deep Neural Network\n",
    "\n",
    "Here we book the new DNN of TMVA. If using master version you can use the new DL method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool useDL = true; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define DNN layout\n",
    "\n",
    "The DNN configuration os defined using a string. Note that whitespaces between characters are not allowed. \n",
    "\n",
    "We define first the DNN layout: \n",
    "\n",
    "- **input layout** :   this defines the input data format for the DNN as  ``input depth | height | width``. \n",
    "   In case of a dense layer as first layer the input layout should be  ``1 | 1 | number of input variables`` (features)\n",
    "- **batch layout**  : this defines how are the input batch. It is related to input layout but not the same. \n",
    "   If the first layer is dense it should be ``1 | batch size ! number of variables`` (fetures)\n",
    "   \n",
    "   *(note the use of the character `|` as  separator of  input parameters for DNN layout)*\n",
    "                 \n",
    "- **layer layout** string defining the layer architecture. The syntax is  \n",
    "   - layer type (e.g. DENSE, CONV, RNN)\n",
    "   - layer parameters (e.g. number of units)\n",
    "   - activation function (e.g  TANH, RELU,...)\n",
    "   \n",
    "     *the different layers are separated by the ``\",\"`` *\n",
    "                \n",
    "#### 2. Define Trainining Strategy\n",
    "\n",
    "We define here the training strategy parameters for the DNN. The parameters are separated by the ``\",\"`` separator. \n",
    "One can then concatenate different training strategy with different parameters. The training strategy are separated by \n",
    "the ``\"|\"`` separator. \n",
    "\n",
    " - Optimizer\n",
    " - Learning rate\n",
    " - Momentum (valid for SGD and RMSPROP)\n",
    " - Regularization and Weight Decay \n",
    " - Dropout \n",
    " - Max number of epochs \n",
    " - Convergence steps. if the test error will not decrease after that value the training will stop\n",
    " - Batch size (This value must be the same specified in the input layout)\n",
    " - Test Repetitions (the interval when the test error will be computed) \n",
    "\n",
    "\n",
    "#### 3. Define general DNN options\n",
    "\n",
    "We define the general DNN options concateneting in the final string the previously defined layout and training strategy.\n",
    "Note we use the ``\":\"`` separator to separate the different higher level options, as in the other TMVA methods. \n",
    "In addition to input layout, batch layout and training strategy we add now: \n",
    "\n",
    "- Type of Loss function (e.g. cross entropy)\n",
    "- Weight Initizalization (e.g XAVIER, XAVIERUNIFORM, NORMAL )\n",
    "- Variable Transformation\n",
    "- Type of Architecture (e.g. CPU, GPU, Standard)\n",
    "\n",
    "We can then book the DL method using the built otion string\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_CPU\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIER:InputLayout=1|1|7:BatchLayout=1|128|7:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIER:InputLayout=1|1|7:BatchLayout=1|128|7:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.:Architecture=CPU\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"G\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|1|7\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"1|128|7\" [The Layout of the batch]\n",
      "                         :     Layout: \"DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIER\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "DL_CPU                   : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "if (useDL) {  \n",
    "     // Define DNN layout\n",
    "     TString inputLayoutString = \"InputLayout=1|1|7\"; \n",
    "     TString batchLayoutString= \"BatchLayout=1|128|7\";\n",
    "     TString layoutString (\"Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\");\n",
    "                                                                                                                                                                                    \n",
    "      // Define Training strategies \n",
    "      // one can catenate several training strategies \n",
    "      TString training1(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    "                        \"ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,\"\n",
    "                        \"MaxEpochs=30,WeightDecay=1e-4,Regularization=None,\"\n",
    "                        \"Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.\");\n",
    " //     TString training2(\"LearningRate=1e-3,Momentum=0.9,Repetitions=1,\"\n",
    " //                       \"ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,\"\n",
    " //                       \"MaxEpochs=20,WeightDecay=1e-4,Regularization=None,\"\n",
    " //                       \"Optimizer=SGD,DropConfig=0.0+0.0+0.0+0.\");\n",
    "  \n",
    "      TString trainingStrategyString (\"TrainingStrategy=\");\n",
    "      trainingStrategyString += training1; // + \"|\" + training2;\n",
    "\n",
    "      // General Options.                                                                                                                                                                \n",
    "      TString dnnOptions (\"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:\"\n",
    "                          \"WeightInitialization=XAVIER\");\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (inputLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (batchLayoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (layoutString);\n",
    "      dnnOptions.Append (\":\"); dnnOptions.Append (trainingStrategyString);\n",
    "\n",
    "      dnnOptions += \":Architecture=CPU\";\n",
    "      factory.BookMethod(loader, TMVA::Types::kDL, \"DL_CPU\", dnnOptions);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Methods\n",
    "\n",
    "Here we train all the previously booked methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:     1.0343    0.66733   [    0.12185     17.681 ]\n",
      "                         :    m_jjj:     1.0249    0.37660   [    0.38832     8.8785 ]\n",
      "                         :     m_lv:     1.0502    0.16023   [    0.26740     3.7622 ]\n",
      "                         :    m_jlv:     1.0053    0.40002   [    0.18584     6.1276 ]\n",
      "                         :     m_bb:    0.97294    0.52590   [   0.078035     7.6805 ]\n",
      "                         :    m_wbb:     1.0321    0.36279   [    0.39760     6.1879 ]\n",
      "                         :   m_wwbb:    0.96138    0.31610   [    0.44969     5.1146 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------\n",
      "                         : Rank : Variable  : Separation\n",
      "                         : -------------------------------\n",
      "                         :    1 : m_bb      : 9.945e-02\n",
      "                         :    2 : m_wwbb    : 4.470e-02\n",
      "                         :    3 : m_wbb     : 4.056e-02\n",
      "                         :    4 : m_jjj     : 2.376e-02\n",
      "                         :    5 : m_jlv     : 1.811e-02\n",
      "                         :    6 : m_lv      : 3.128e-03\n",
      "                         :    7 : m_jj      : 2.809e-03\n",
      "                         : -------------------------------\n",
      "Factory                  : Train method: LikelihoodKDE for Classification\n",
      "                         : \n",
      "                         : Filling reference histograms\n",
      "                         : Building PDF out of reference histograms\n",
      "                         : Elapsed time for training with 14000 events: 14.5 sec         \n",
      "LikelihoodKDE            : [dataset] : Evaluation of LikelihoodKDE on training sample (14000 events)\n",
      "                         : Elapsed time for evaluation of 14000 events: 0.0231 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_LikelihoodKDE.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_LikelihoodKDE.class.C\u001b[0m\n",
      "                         : Write monitoring histograms to file: Higgs_ClassificationOutput.root:/dataset/Method_LikelihoodKDE/LikelihoodKDE\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: Fisher for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ Fisher ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : Fisher discriminants select events by distinguishing the mean \n",
      "                         : values of the signal and background distributions in a trans- \n",
      "                         : formed variable space where linear correlations are removed.\n",
      "                         : \n",
      "                         :    (More precisely: the \"linear discriminator\" determines\n",
      "                         :     an axis in the (correlated) hyperspace of the input \n",
      "                         :     variables such that, when projecting the output classes \n",
      "                         :     (signal and background) upon this axis, they are pushed \n",
      "                         :     as far as possible away from each other, while events\n",
      "                         :     of a same class are confined in a close vicinity. The  \n",
      "                         :     linearity property of this classifier is reflected in the \n",
      "                         :     metric with which \"far apart\" and \"close vicinity\" are \n",
      "                         :     determined: the covariance matrix of the discriminating\n",
      "                         :     variable space.)\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : Optimal performance for Fisher discriminants is obtained for \n",
      "                         : linearly correlated Gaussian-distributed variables. Any deviation\n",
      "                         : from this ideal reduces the achievable separation power. In \n",
      "                         : particular, no discrimination at all is achieved for a variable\n",
      "                         : that has the same sample mean for signal and background, even if \n",
      "                         : the shapes of the distributions are very different. Thus, Fisher \n",
      "                         : discriminants often benefit from suitable transformations of the \n",
      "                         : input variables. For example, if a variable x in [-1,1] has a \n",
      "                         : a parabolic signal distributions, and a uniform background\n",
      "                         : distributions, their mean value is zero in both cases, leading \n",
      "                         : to no separation. The simple transformation x -> |x| renders this \n",
      "                         : variable powerful for the use in a Fisher discriminant.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : <None>\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "Fisher                   : Results for Fisher coefficients:\n",
      "                         : -----------------------\n",
      "                         : Variable:  Coefficient:\n",
      "                         : -----------------------\n",
      "                         :     m_jj:       -0.028\n",
      "                         :    m_jjj:       +0.165\n",
      "                         :     m_lv:       +0.009\n",
      "                         :    m_jlv:       +0.073\n",
      "                         :     m_bb:       -0.206\n",
      "                         :    m_wbb:       +0.494\n",
      "                         :   m_wwbb:       -0.711\n",
      "                         : (offset):       +0.152\n",
      "                         : -----------------------\n",
      "                         : Elapsed time for training with 14000 events: 0.00933 sec         \n",
      "Fisher                   : [dataset] : Evaluation of Fisher on training sample (14000 events)\n",
      "                         : Elapsed time for evaluation of 14000 events: 0.000977 sec       \n",
      "                         : Dataset[dataset] : <CreateMVAPdfs> Separation from histogram (PDF): 0.088 (0.000)\n",
      "                         : Dataset[dataset] : Evaluation of Fisher on training sample\n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Fisher.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Fisher.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: BDT for Classification\n",
      "                         : \n",
      "BDT                      : #events: (reweighted) sig: 7000 bkg: 7000\n",
      "                         : #events: (unweighted) sig: 7000 bkg: 7000\n",
      "                         : Training 200 Decision Trees ... patience please\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         : Elapsed time for training with 14000 events: 7.05 sec         \n",
      "BDT                      : [dataset] : Evaluation of BDT on training sample (14000 events)\n",
      "                         : Elapsed time for evaluation of 14000 events: 0.193 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_BDT.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: MLP for Classification\n",
      "                         : \n",
      "TFHandler_MLP            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:   -0.89607   0.076010   [    -1.0000     1.0000 ]\n",
      "                         :    m_jjj:   -0.85005   0.088715   [    -1.0000     1.0000 ]\n",
      "                         :     m_lv:   -0.55203   0.091697   [    -1.0000     1.0000 ]\n",
      "                         :    m_jlv:   -0.72418    0.13465   [    -1.0000     1.0000 ]\n",
      "                         :     m_bb:   -0.76458    0.13835   [    -1.0000     1.0000 ]\n",
      "                         :    m_wbb:   -0.78084    0.12531   [    -1.0000     1.0000 ]\n",
      "                         :   m_wwbb:   -0.78062    0.13552   [    -1.0000     1.0000 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Training Network\n",
      "                         : \n",
      "                         : Elapsed time for training with 14000 events: 7.83 sec         \n",
      "MLP                      : [dataset] : Evaluation of MLP on training sample (14000 events)\n",
      "                         : Elapsed time for evaluation of 14000 events: 0.023 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_MLP.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_MLP.class.C\u001b[0m\n",
      "                         : Write special histos to file: Higgs_ClassificationOutput.root:/dataset/Method_MLP/MLP\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: DL_CPU for Classification\n",
      "                         : \n",
      "                         : Preparing the Gaussian transformation...\n",
      "TFHandler_DL_CPU         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:  0.0043756    0.99826   [    -3.2803     5.7307 ]\n",
      "                         :    m_jjj:  0.0043779    0.99849   [    -3.2803     5.7307 ]\n",
      "                         :     m_lv:  0.0046252    0.99830   [    -3.2807     5.7307 ]\n",
      "                         :    m_jlv:  0.0045692    0.99870   [    -3.2806     5.7307 ]\n",
      "                         :     m_bb:  0.0046938    0.99993   [    -3.2796     5.7307 ]\n",
      "                         :    m_wbb:  0.0043245    0.99837   [    -3.2801     5.7307 ]\n",
      "                         :   m_wwbb:  0.0044804    0.99914   [    -3.2798     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Start of deep neural network training on CPU.\n",
      "                         : \n",
      "TFHandler_DL_CPU         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:  0.0043756    0.99826   [    -3.2803     5.7307 ]\n",
      "                         :    m_jjj:  0.0043779    0.99849   [    -3.2803     5.7307 ]\n",
      "                         :     m_lv:  0.0046252    0.99830   [    -3.2807     5.7307 ]\n",
      "                         :    m_jlv:  0.0045692    0.99870   [    -3.2806     5.7307 ]\n",
      "                         :     m_bb:  0.0046938    0.99993   [    -3.2796     5.7307 ]\n",
      "                         :    m_wbb:  0.0043245    0.99837   [    -3.2801     5.7307 ]\n",
      "                         :   m_wwbb:  0.0044804    0.99914   [    -3.2798     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "TFHandler_DL_CPU         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:   0.012144    0.99779   [    -3.0904     3.5413 ]\n",
      "                         :    m_jjj:   0.010246    0.99646   [    -3.0512     3.5492 ]\n",
      "                         :     m_lv:  -0.016454    0.99928   [    -3.1397     5.7307 ]\n",
      "                         :    m_jlv:   0.033881    0.99533   [    -2.9994     5.7307 ]\n",
      "                         :     m_bb: 0.00079087     1.0037   [    -2.9893     3.3944 ]\n",
      "                         :    m_wbb:   0.019299     1.0049   [    -3.1990     5.7307 ]\n",
      "                         :   m_wwbb:   0.023980    0.99576   [    -3.6605     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : *****   Deep Learning Network *****\n",
      "DEEP NEURAL NETWORK:   Depth = 5  Input = ( 1, 1, 7 )  Batch size = 128  Loss function = C\n",
      "\tLayer 0\t DENSE Layer: \t  ( Input = 7 , Width = 64 ) \tOutput = ( 1 , 128 , 64 ) \t Activation Function = Tanh\n",
      "\tLayer 1\t DENSE Layer: \t  ( Input = 64 , Width = 64 ) \tOutput = ( 1 , 128 , 64 ) \t Activation Function = Tanh\n",
      "\tLayer 2\t DENSE Layer: \t  ( Input = 64 , Width = 64 ) \tOutput = ( 1 , 128 , 64 ) \t Activation Function = Tanh\n",
      "\tLayer 3\t DENSE Layer: \t  ( Input = 64 , Width = 64 ) \tOutput = ( 1 , 128 , 64 ) \t Activation Function = Tanh\n",
      "\tLayer 4\t DENSE Layer: \t  ( Input = 64 , Width = 1 ) \tOutput = ( 1 , 128 , 1 ) \t Activation Function = Identity\n",
      "                         : Training phase 1 of 1:    Learning rate = 0.001 regularization 0 minimum error = 0.703659\n",
      "                         : --------------------------------------------------------------\n",
      "                         :      Epoch |   Train Err.   Test Err.  t(s)/epoch   t(s)/Loss   nEvents/s Conv. Steps\n",
      "                         : --------------------------------------------------------------\n",
      "                         :          1 Minimum Test error found - save the configuration \n",
      "                         :          1 |     0.631591    0.637969     13.6956     6.49467     1937.53           0\n",
      "                         :          2 Minimum Test error found - save the configuration \n",
      "                         :          2 |     0.609198    0.616387     13.2989     6.30139     1993.85           0\n",
      "                         :          3 Minimum Test error found - save the configuration \n",
      "                         :          3 |     0.597369    0.604357     14.0012     6.80388     1938.51           0\n",
      "                         :          4 Minimum Test error found - save the configuration \n",
      "                         :          4 |     0.588563    0.596988     14.3992     6.89774      1859.9           0\n",
      "                         :          5 Minimum Test error found - save the configuration \n",
      "                         :          5 |     0.583784    0.592042     14.6029     6.80551     1789.33           0\n",
      "                         :          6 Minimum Test error found - save the configuration \n",
      "                         :          6 |     0.578785    0.587967     14.6973     6.90302     1790.03           0\n",
      "                         :          7 Minimum Test error found - save the configuration \n",
      "                         :          7 |     0.576598     0.58595      14.598     6.69552     1765.53           0\n",
      "                         :          8 Minimum Test error found - save the configuration \n",
      "                         :          8 |     0.574402     0.58394     14.3014     6.50261     1789.01           0\n",
      "                         :          9 Minimum Test error found - save the configuration \n",
      "                         :          9 |     0.571733    0.581068          14     6.39563     1834.73           0\n",
      "                         :         10 Minimum Test error found - save the configuration \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         :         10 |      0.57118    0.581023     13.1002     6.30201     2052.33           0\n",
      "                         :         11 Minimum Test error found - save the configuration \n",
      "                         :         11 |     0.570033    0.578951     13.9967     6.79997     1938.66           0\n",
      "                         :         12 Minimum Test error found - save the configuration \n",
      "                         :         12 |     0.568436    0.577886     13.5993     6.59683     1992.45           0\n",
      "                         :         13 Minimum Test error found - save the configuration \n",
      "                         :         13 |     0.567281    0.577095     14.3039     6.60228     1811.56           0\n",
      "                         :         14 Minimum Test error found - save the configuration \n",
      "                         :         14 |     0.566226    0.576768     14.8987     7.19465     1810.99           0\n",
      "                         :         15 Minimum Test error found - save the configuration \n",
      "                         :         15 |     0.566221    0.576217     14.2059     6.60431      1835.4           0\n",
      "                         :         16 Minimum Test error found - save the configuration \n",
      "                         :         16 |     0.564448    0.573455     10.9948     4.69321     2214.04           0\n",
      "                         :         17 |     0.564757    0.574851     14.4966     7.29516     1937.38           1\n",
      "                         :         18 Minimum Test error found - save the configuration \n",
      "                         :         18 |     0.562032    0.572247     13.4995     6.00075     1860.57           0\n",
      "                         :         19 |     0.563229    0.572716     12.2059     6.00528      2250.1           1\n",
      "                         :         20 Minimum Test error found - save the configuration \n",
      "                         :         20 |     0.561833    0.571808     12.3944     6.09952     2216.41           0\n",
      "                         :         21 Minimum Test error found - save the configuration \n",
      "                         :         21 |      0.56004    0.571054     14.0977     6.59803     1860.34           0\n",
      "                         :         22 Minimum Test error found - save the configuration \n",
      "                         :         22 |     0.558683    0.569067     14.0086     6.50558     1859.53           0\n",
      "                         :         23 Minimum Test error found - save the configuration \n",
      "                         :         23 |     0.558964     0.56896     14.2932     6.29804     1745.05           0\n",
      "                         :         24 |     0.558886    0.569664     14.7012      6.7993     1765.65           1\n",
      "                         :         25 |     0.558733    0.569282          12     6.10064     2365.01           2\n",
      "                         :         26 Minimum Test error found - save the configuration \n",
      "                         :         26 |      0.55687    0.568207     11.7054      5.3019     2178.82           0\n",
      "                         :         27 |      0.55828      0.5686     12.2908     6.28924     2324.74           1\n",
      "                         :         28 Minimum Test error found - save the configuration \n",
      "                         :         28 |     0.555435    0.566668     13.4116     6.20815     1936.85           0\n",
      "                         :         29 |      0.55609    0.567381     13.9898     6.49422     1861.36           1\n",
      "                         :         30 Minimum Test error found - save the configuration \n",
      "                         :         30 |     0.554387    0.566143     13.2029     6.30188     2021.73           0\n",
      "                         : \n",
      "                         : Elapsed time for training with 14000 events: 411 sec         \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 128\n",
      "                         : \n",
      "DL_CPU                   : [dataset] : Evaluation of DL_CPU on training sample (14000 events)\n",
      "                         : Elapsed time for evaluation of 14000 events: 4.18 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_DL_CPU.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_DL_CPU.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "LikelihoodKDE            : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable  : Delta Separation\n",
      "                         : -------------------------------------\n",
      "                         :    1 : m_bb      : 5.169e-02\n",
      "                         :    2 : m_jjj     : 1.974e-02\n",
      "                         :    3 : m_jlv     : 9.537e-03\n",
      "                         :    4 : m_wwbb    : 2.654e-03\n",
      "                         :    5 : m_jj      : 2.615e-03\n",
      "                         :    6 : m_lv      : 2.245e-03\n",
      "                         :    7 : m_wbb     : -6.447e-03\n",
      "                         : -------------------------------------\n",
      "Fisher                   : Ranking result (top variable is best ranked)\n",
      "                         : ---------------------------------\n",
      "                         : Rank : Variable  : Discr. power\n",
      "                         : ---------------------------------\n",
      "                         :    1 : m_bb      : 1.214e-02\n",
      "                         :    2 : m_wwbb    : 7.674e-03\n",
      "                         :    3 : m_wbb     : 2.273e-03\n",
      "                         :    4 : m_jlv     : 5.766e-04\n",
      "                         :    5 : m_jjj     : 2.982e-04\n",
      "                         :    6 : m_jj      : 1.465e-04\n",
      "                         :    7 : m_lv      : 1.225e-05\n",
      "                         : ---------------------------------\n",
      "BDT                      : Ranking result (top variable is best ranked)\n",
      "                         : ----------------------------------------\n",
      "                         : Rank : Variable  : Variable Importance\n",
      "                         : ----------------------------------------\n",
      "                         :    1 : m_bb      : 1.940e-01\n",
      "                         :    2 : m_wwbb    : 1.670e-01\n",
      "                         :    3 : m_jlv     : 1.541e-01\n",
      "                         :    4 : m_jjj     : 1.490e-01\n",
      "                         :    5 : m_wbb     : 1.431e-01\n",
      "                         :    6 : m_jj      : 1.139e-01\n",
      "                         :    7 : m_lv      : 7.885e-02\n",
      "                         : ----------------------------------------\n",
      "MLP                      : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------\n",
      "                         : Rank : Variable  : Importance\n",
      "                         : -------------------------------\n",
      "                         :    1 : m_bb      : 2.011e+02\n",
      "                         :    2 : m_wbb     : 1.110e+02\n",
      "                         :    3 : m_wwbb    : 7.960e+01\n",
      "                         :    4 : m_jj      : 2.609e+01\n",
      "                         :    5 : m_jjj     : 2.438e+01\n",
      "                         :    6 : m_jlv     : 1.734e+01\n",
      "                         :    7 : m_lv      : 3.344e+00\n",
      "                         : -------------------------------\n",
      "                         : No variable ranking supplied by classifier: DL_CPU\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_LikelihoodKDE.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Fisher.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_BDT.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_MLP.weights.xml\u001b[0m\n",
      "MLP                      : Building Network. \n",
      "                         : Initializing weights\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_DL_CPU.weights.xml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test  all methods\n",
    "\n",
    "Here we test all methods using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: LikelihoodKDE for Classification performance\n",
      "                         : \n",
      "LikelihoodKDE            : [dataset] : Evaluation of LikelihoodKDE on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.0136 sec       \n",
      "Factory                  : Test method: Fisher for Classification performance\n",
      "                         : \n",
      "Fisher                   : [dataset] : Evaluation of Fisher on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.000619 sec       \n",
      "                         : Dataset[dataset] : Evaluation of Fisher on testing sample\n",
      "Factory                  : Test method: BDT for Classification performance\n",
      "                         : \n",
      "BDT                      : [dataset] : Evaluation of BDT on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.0464 sec       \n",
      "Factory                  : Test method: MLP for Classification performance\n",
      "                         : \n",
      "MLP                      : [dataset] : Evaluation of MLP on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.01 sec       \n",
      "Factory                  : Test method: DL_CPU for Classification performance\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DL_CPU         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:   0.012144    0.99779   [    -3.0904     3.5413 ]\n",
      "                         :    m_jjj:   0.010246    0.99646   [    -3.0512     3.5492 ]\n",
      "                         :     m_lv:  -0.016454    0.99928   [    -3.1397     5.7307 ]\n",
      "                         :    m_jlv:   0.033881    0.99533   [    -2.9994     5.7307 ]\n",
      "                         :     m_bb: 0.00079087     1.0037   [    -2.9893     3.3944 ]\n",
      "                         :    m_wbb:   0.019299     1.0049   [    -3.1990     5.7307 ]\n",
      "                         :   m_wwbb:   0.023980    0.99576   [    -3.6605     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "DL_CPU                   : [dataset] : Evaluation of DL_CPU on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.629 sec       \n"
     ]
    }
   ],
   "source": [
    "factory.TestAllMethods();   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate all methods\n",
    "\n",
    "Here we evaluate all methods and compare their performances, computing efficiencies, ROC curves etc.. using both training and tetsing data sets. Several histograms are produced which can be examined with the TMVAGui or directly using the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: LikelihoodKDE\n",
      "                         : \n",
      "LikelihoodKDE            : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_LikelihoodKDE  : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:     1.0366    0.65486   [    0.15013     11.620 ]\n",
      "                         :    m_jjj:     1.0265    0.37636   [    0.42274     6.1198 ]\n",
      "                         :     m_lv:     1.0487    0.16464   [    0.37639     3.2362 ]\n",
      "                         :    m_jlv:     1.0143    0.41840   [    0.36042     8.6965 ]\n",
      "                         :     m_bb:    0.97178    0.51585   [    0.10107     5.4735 ]\n",
      "                         :    m_wbb:     1.0375    0.37146   [    0.40481     6.1312 ]\n",
      "                         :   m_wwbb:    0.96608    0.31992   [    0.43841     4.2448 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: Fisher\n",
      "                         : \n",
      "Fisher                   : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Also filling probability and rarity histograms (on request)...\n",
      "TFHandler_Fisher         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:     1.0366    0.65486   [    0.15013     11.620 ]\n",
      "                         :    m_jjj:     1.0265    0.37636   [    0.42274     6.1198 ]\n",
      "                         :     m_lv:     1.0487    0.16464   [    0.37639     3.2362 ]\n",
      "                         :    m_jlv:     1.0143    0.41840   [    0.36042     8.6965 ]\n",
      "                         :     m_bb:    0.97178    0.51585   [    0.10107     5.4735 ]\n",
      "                         :    m_wbb:     1.0375    0.37146   [    0.40481     6.1312 ]\n",
      "                         :   m_wwbb:    0.96608    0.31992   [    0.43841     4.2448 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: BDT\n",
      "                         : \n",
      "BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_BDT            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:     1.0366    0.65486   [    0.15013     11.620 ]\n",
      "                         :    m_jjj:     1.0265    0.37636   [    0.42274     6.1198 ]\n",
      "                         :     m_lv:     1.0487    0.16464   [    0.37639     3.2362 ]\n",
      "                         :    m_jlv:     1.0143    0.41840   [    0.36042     8.6965 ]\n",
      "                         :     m_bb:    0.97178    0.51585   [    0.10107     5.4735 ]\n",
      "                         :    m_wbb:     1.0375    0.37146   [    0.40481     6.1312 ]\n",
      "                         :   m_wwbb:    0.96608    0.31992   [    0.43841     4.2448 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: MLP\n",
      "                         : \n",
      "TFHandler_MLP            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:   -0.89581   0.074590   [   -0.99678    0.30963 ]\n",
      "                         :    m_jjj:   -0.84968   0.088657   [   -0.99189    0.35014 ]\n",
      "                         :     m_lv:   -0.55286   0.094221   [   -0.93763    0.69900 ]\n",
      "                         :    m_jlv:   -0.72115    0.14083   [   -0.94124     1.8647 ]\n",
      "                         :     m_bb:   -0.76488    0.13571   [   -0.99394    0.41939 ]\n",
      "                         :    m_wbb:   -0.77896    0.12830   [   -0.99751    0.98044 ]\n",
      "                         :   m_wwbb:   -0.77861    0.13716   [    -1.0048    0.62707 ]\n",
      "                         : -----------------------------------------------------------\n",
      "MLP                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_MLP            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:   -0.89581   0.074590   [   -0.99678    0.30963 ]\n",
      "                         :    m_jjj:   -0.84968   0.088657   [   -0.99189    0.35014 ]\n",
      "                         :     m_lv:   -0.55286   0.094221   [   -0.93763    0.69900 ]\n",
      "                         :    m_jlv:   -0.72115    0.14083   [   -0.94124     1.8647 ]\n",
      "                         :     m_bb:   -0.76488    0.13571   [   -0.99394    0.41939 ]\n",
      "                         :    m_wbb:   -0.77896    0.12830   [   -0.99751    0.98044 ]\n",
      "                         :   m_wwbb:   -0.77861    0.13716   [    -1.0048    0.62707 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: DL_CPU\n",
      "                         : \n",
      "DL_CPU                   : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Evaluate deep neural network on CPU using batches with size = 1000\n",
      "                         : \n",
      "TFHandler_DL_CPU         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:  0.0043756    0.99826   [    -3.2803     5.7307 ]\n",
      "                         :    m_jjj:  0.0043779    0.99849   [    -3.2803     5.7307 ]\n",
      "                         :     m_lv:  0.0046252    0.99830   [    -3.2807     5.7307 ]\n",
      "                         :    m_jlv:  0.0045692    0.99870   [    -3.2806     5.7307 ]\n",
      "                         :     m_bb:  0.0046938    0.99993   [    -3.2796     5.7307 ]\n",
      "                         :    m_wbb:  0.0043245    0.99837   [    -3.2801     5.7307 ]\n",
      "                         :   m_wwbb:  0.0044804    0.99914   [    -3.2798     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "TFHandler_DL_CPU         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :     m_jj:   0.012144    0.99779   [    -3.0904     3.5413 ]\n",
      "                         :    m_jjj:   0.010246    0.99646   [    -3.0512     3.5492 ]\n",
      "                         :     m_lv:  -0.016454    0.99928   [    -3.1397     5.7307 ]\n",
      "                         :    m_jlv:   0.033881    0.99533   [    -2.9994     5.7307 ]\n",
      "                         :     m_bb: 0.00079087     1.0037   [    -2.9893     3.3944 ]\n",
      "                         :    m_wbb:   0.019299     1.0049   [    -3.1990     5.7307 ]\n",
      "                         :   m_wwbb:   0.023980    0.99576   [    -3.6605     5.7307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       DL_CPU         : 0.773\n",
      "                         : dataset       BDT            : 0.759\n",
      "                         : dataset       MLP            : 0.727\n",
      "                         : dataset       LikelihoodKDE  : 0.707\n",
      "                         : dataset       Fisher         : 0.646\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              DL_CPU         : 0.129 (0.126)       0.411 (0.429)      0.696 (0.701)\n",
      "                         : dataset              BDT            : 0.097 (0.110)       0.400 (0.426)      0.672 (0.677)\n",
      "                         : dataset              MLP            : 0.032 (0.040)       0.363 (0.360)      0.643 (0.645)\n",
      "                         : dataset              LikelihoodKDE  : 0.085 (0.078)       0.355 (0.360)      0.590 (0.600)\n",
      "                         : dataset              Fisher         : 0.011 (0.015)       0.115 (0.118)      0.510 (0.507)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 6000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 14000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.EvaluateAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "We enable JavaScript visualisation for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "//%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAHYCAIAAAApvgy/AAAABmJLR0QAAAAAAAD5Q7t/AAAgAElE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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1 = factory.GetROCCurve(loader);\n",
    "c1->Draw();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Close outputfile to save all output information (evaluation result of methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFile->Close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
