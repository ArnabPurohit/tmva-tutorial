{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://oproject.org/tiki-download_file.php?fileId=8&display&x=450&y=128\">\n",
    "<img src=\"http://files.oproject.org/tmvalogo.png\" height=\"50%\" width=\"50%\">\n",
    "\n",
    "# TMVA Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods\n",
    "whose performance you'd like to investigate. \n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    " - The first argument is the base of the name of all the output\n",
    "weightfiles in the directory weight/ that will be created with the \n",
    "method parameters \n",
    "\n",
    " - The second argument is the output file for the training results\n",
    "  \n",
    " - The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMVA::Tools::Instance();\n",
    "\n",
    "\n",
    "auto outputFile = TFile::Open(\"TMVA_ClassificationOutput.root\", \"RECREATE\");\n",
    "\n",
    "TMVA::Factory factory(\"TMVAClassification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" ); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup input Dataset\n",
    "\n",
    "Define input data file and signal and background trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TString inputFileName = \"http://root.cern.ch/files/tmva_class_example.root\";\n",
    "//TString inputFileName = \"tmva_class_example.root\";\n",
    "\n",
    "auto inputFile = TFile::Open( inputFileName );\n",
    "\n",
    "// --- Register the training and test trees\n",
    "\n",
    "TTree *signalTree     = (TTree*)inputFile->Get(\"TreeS\");\n",
    "TTree *backgroundTree = (TTree*)inputFile->Get(\"TreeB\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "The next step is to declare the DataLoader class which provides the interface from TMVA to the input data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMVA::DataLoader * loader = new TMVA::DataLoader(\"dataset\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree TreeS of type Signal with 6000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree TreeB of type Background with 6000 events\n"
     ]
    }
   ],
   "source": [
    "// global event weights per tree (see below for setting event-wise weights)\n",
    "Double_t signalWeight     = 1.0;\n",
    "Double_t backgroundWeight = 1.0;\n",
    "   \n",
    "// You can add an arbitrary number of signal or background trees\n",
    "loader->AddSignalTree    ( signalTree,     signalWeight     );\n",
    "loader->AddBackgroundTree( backgroundTree, backgroundWeight );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input variables\n",
    "\n",
    "Through the DataLoader we define the input variables that will be used for the MVA training.\n",
    "Note that we can also use variable expressions, which can be parsed by *TTree::Draw( \"expression\" )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader->AddVariable( \"myvar1 := var1+var2\", 'F' );\n",
    "loader->AddVariable( \"myvar2 := var1-var2\", \"Expression 2\", \"\", 'F' );\n",
    "loader->AddVariable( \"var3\",                \"Variable 3\", \"units\", 'F' );\n",
    "loader->AddVariable( \"var4\",                \"Variable 4\", \"units\", 'F' );\n",
    "\n",
    "// You can add so-called \"Spectator variables\", which are not used in the MVA training,\n",
    "// but will appear in the final \"TestTree\" produced by TMVA. This TestTree will contain the\n",
    "// input variables, the response values of all trained MVAs, and the spectator variables\n",
    "loader->AddSpectator( \"spec1 := var1*2\",  \"Spectator 1\", \"units\", 'F' );\n",
    "loader->AddSpectator( \"spec2 := var1*3\",  \"Spectator 2\", \"units\", 'F' );\n",
    "\n",
    "\n",
    "//  We can define also the event weights\n",
    "\n",
    "// Set individual event weights (the variables must exist in the original TTree)\n",
    "//    for signal    : factory->SetSignalWeightExpression    (\"weight1*weight2\");\n",
    "//    for background: factory->SetBackgroundWeightExpression(\"weight1*weight2\");\n",
    "loader->SetBackgroundWeightExpression( \"weight\" );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data splitting in training and test sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Apply additional cuts on the signal and background samples (can be different)\n",
    "TCut mycuts = \"\"; // for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "TCut mycutb = \"\"; // for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "// Tell the factory how to use the training and testing events\n",
    "//\n",
    "// If no numbers of events are given, half of the events in the tree are used \n",
    "// for training, and the other half for testing:\n",
    "//    loader->PrepareTrainingAndTestTree( mycut, \"SplitMode=random:!V\" );\n",
    "// To also specify the number of testing events, use:\n",
    "//    loader->PrepareTrainingAndTestTree( mycut,\n",
    "//                                         \"NSigTrain=3000:NBkgTrain=3000:NSigTest=3000:NBkgTest=3000:SplitMode=Random:!V\" );\n",
    "loader->PrepareTrainingAndTestTree( mycuts, mycutb,\n",
    "                                    \"nTrain_Signal=0:nTrain_Background=0:SplitMode=Random:NormMode=NumEvents:!V\" );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Methods\n",
    "\n",
    "\n",
    "We Book here the different MVA method we want to use. \n",
    "We specify the method using the appropriate enumeration, defined in *TMVA::Types*.\n",
    "See the file *TMVA/Types.h* for all possible MVA methods available. \n",
    "In addition, we specify via an option string all the method parameters. For all possible options, default parameter values, see the corresponding documentation in the TMVA Users Guide. \n",
    "\n",
    "Note that with the booking one can also specify individual variable tranformations to be done before using the method.\n",
    "For example *VarTransform=Decorrelate* will decorrelate the inputs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mLikelihood\u001b[0m\n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mLikelihoodKDE\u001b[0m\n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mFisher\u001b[0m\n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 3000\n",
      "                         : Signal     -- testing events             : 3000\n",
      "                         : Signal     -- training and testing events: 6000\n",
      "                         : Background -- training events            : 3000\n",
      "                         : Background -- testing events             : 3000\n",
      "                         : Background -- training and testing events: 6000\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ----------------------------------------------\n",
      "                         :            var1+var2 var1-var2    var3    var4\n",
      "                         : var1+var2:    +1.000    -0.009  +0.773  +0.926\n",
      "                         : var1-var2:    -0.009    +1.000  -0.095  +0.066\n",
      "                         :      var3:    +0.773    -0.095  +1.000  +0.852\n",
      "                         :      var4:    +0.926    +0.066  +0.852  +1.000\n",
      "                         : ----------------------------------------------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ----------------------------------------------\n",
      "                         :            var1+var2 var1-var2    var3    var4\n",
      "                         : var1+var2:    +1.000    +0.008  +0.785  +0.930\n",
      "                         : var1-var2:    +0.008    +1.000  -0.087  +0.092\n",
      "                         :      var3:    +0.785    -0.087  +1.000  +0.852\n",
      "                         :      var4:    +0.930    +0.092  +0.852  +1.000\n",
      "                         : ----------------------------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mMLP\u001b[0m\n",
      "                         : \n",
      "MLP                      : [dataset] : Create Transformation \"N\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "MLP                      : Building Network. \n",
      "                         : Initializing weights\n"
     ]
    }
   ],
   "source": [
    "// Likelihood (\"naive Bayes estimator\")\n",
    "factory.BookMethod(loader, TMVA::Types::kLikelihood, \"Likelihood\",\n",
    "                           \"H:!V:TransformOutput:PDFInterpol=Spline2:NSmoothSig[0]=20:NSmoothBkg[0]=20:NSmoothBkg[1]=10:NSmooth=1:NAvEvtPerBin=50\" );\n",
    "\n",
    "// Use a kernel density estimator to approximate the PDFs\n",
    "factory.BookMethod(loader, TMVA::Types::kLikelihood, \"LikelihoodKDE\",\n",
    "                           \"!H:!V:!TransformOutput:PDFInterpol=KDE:KDEtype=Gauss:KDEiter=Adaptive:KDEFineFactor=0.3:KDEborder=None:NAvEvtPerBin=50\" ); \n",
    "\n",
    "\n",
    "// Fisher discriminant (same as LD)\n",
    "factory.BookMethod(loader, TMVA::Types::kFisher, \"Fisher\", \"H:!V:Fisher:VarTransform=None:CreateMVAPdfs:PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=50:NsmoothMVAPdf=10\" );\n",
    "\n",
    "//Boosted Decision Trees\n",
    "factory.BookMethod(loader,TMVA::Types::kBDT, \"BDT\",\n",
    "                   \"!V:NTrees=200:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" );\n",
    "\n",
    "//Multi-Layer Perceptron (Neural Network)\n",
    "factory.BookMethod(loader, TMVA::Types::kMLP, \"MLP\",\n",
    "                   \"!H:!V:NeuronType=tanh:VarTransform=N:NCycles=100:HiddenLayers=N+5:TestRate=5:!UseRegulator\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train all methods\n",
    "\n",
    "Here we train all previously booked methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'myvar1' <---> Output : variable 'myvar1'\n",
      "                         : Input : variable 'myvar2' <---> Output : variable 'myvar2'\n",
      "                         : Input : variable 'var3' <---> Output : variable 'var3'\n",
      "                         : Input : variable 'var4' <---> Output : variable 'var4'\n",
      "TFHandler_Factory        : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:  -0.019360     1.7427   [    -8.9660     7.6931 ]\n",
      "                         :   myvar2: -0.0098967     1.1059   [    -4.0854     4.0259 ]\n",
      "                         :     var3: -0.0084328     1.0724   [    -5.0508     4.3597 ]\n",
      "                         :     var4:    0.13633     1.2670   [    -5.9505     4.9225 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable     : Separation\n",
      "                         : -------------------------------------\n",
      "                         :    1 : Variable 4   : 2.624e-01\n",
      "                         :    2 : Variable 3   : 1.341e-01\n",
      "                         :    3 : myvar1       : 8.491e-02\n",
      "                         :    4 : Expression 2 : 1.377e-02\n",
      "                         : -------------------------------------\n",
      "Factory                  : Train method: Likelihood for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ Likelihood ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : The maximum-likelihood classifier models the data with probability \n",
      "                         : density functions (PDF) reproducing the signal and background\n",
      "                         : distributions of the input variables. Correlations among the \n",
      "                         : variables are ignored.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : Required for good performance are decorrelated input variables\n",
      "                         : (PCA transformation via the option \"VarTransform=Decorrelate\"\n",
      "                         : may be tried). Irreducible non-linear correlations may be reduced\n",
      "                         : by precombining strongly correlated input variables, or by simply\n",
      "                         : removing one of the variables.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : High fidelity PDF estimates are mandatory, i.e., sufficient training \n",
      "                         : statistics is required to populate the tails of the distributions\n",
      "                         : It would be a surprise if the default Spline or KDE kernel parameters\n",
      "                         : provide a satisfying fit to the data. The user is advised to properly\n",
      "                         : tune the events per bin and smooth options in the spline cases\n",
      "                         : individually per variable. If the KDE kernel is used, the adaptive\n",
      "                         : Gaussian kernel may lead to artefacts, so please always also try\n",
      "                         : the non-adaptive one.\n",
      "                         : \n",
      "                         : All tuning parameters must be adjusted individually for each input\n",
      "                         : variable!\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "                         : Filling reference histograms\n",
      "                         : Building PDF out of reference histograms\n",
      "                         : Elapsed time for training with 6000 events: 0.0489 sec         \n",
      "Likelihood               : [dataset] : Evaluation of Likelihood on training sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.0071 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_Likelihood.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_Likelihood.class.C\u001b[0m\n",
      "                         : Write monitoring histograms to file: TMVA_ClassificationOutput.root:/dataset/Method_Likelihood/Likelihood\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: LikelihoodKDE for Classification\n",
      "                         : \n",
      "                         : Filling reference histograms\n",
      "                         : Building PDF out of reference histograms\n",
      "                         : Elapsed time for training with 6000 events: 3.61 sec         \n",
      "LikelihoodKDE            : [dataset] : Evaluation of LikelihoodKDE on training sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.00923 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_LikelihoodKDE.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_LikelihoodKDE.class.C\u001b[0m\n",
      "                         : Write monitoring histograms to file: TMVA_ClassificationOutput.root:/dataset/Method_LikelihoodKDE/LikelihoodKDE\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: Fisher for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ Fisher ] :\u001b[0m\n",
      "                         : \n",
      "                         : \u001b[1m--- Short description:\u001b[0m\n",
      "                         : \n",
      "                         : Fisher discriminants select events by distinguishing the mean \n",
      "                         : values of the signal and background distributions in a trans- \n",
      "                         : formed variable space where linear correlations are removed.\n",
      "                         : \n",
      "                         :    (More precisely: the \"linear discriminator\" determines\n",
      "                         :     an axis in the (correlated) hyperspace of the input \n",
      "                         :     variables such that, when projecting the output classes \n",
      "                         :     (signal and background) upon this axis, they are pushed \n",
      "                         :     as far as possible away from each other, while events\n",
      "                         :     of a same class are confined in a close vicinity. The  \n",
      "                         :     linearity property of this classifier is reflected in the \n",
      "                         :     metric with which \"far apart\" and \"close vicinity\" are \n",
      "                         :     determined: the covariance matrix of the discriminating\n",
      "                         :     variable space.)\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance optimisation:\u001b[0m\n",
      "                         : \n",
      "                         : Optimal performance for Fisher discriminants is obtained for \n",
      "                         : linearly correlated Gaussian-distributed variables. Any deviation\n",
      "                         : from this ideal reduces the achievable separation power. In \n",
      "                         : particular, no discrimination at all is achieved for a variable\n",
      "                         : that has the same sample mean for signal and background, even if \n",
      "                         : the shapes of the distributions are very different. Thus, Fisher \n",
      "                         : discriminants often benefit from suitable transformations of the \n",
      "                         : input variables. For example, if a variable x in [-1,1] has a \n",
      "                         : a parabolic signal distributions, and a uniform background\n",
      "                         : distributions, their mean value is zero in both cases, leading \n",
      "                         : to no separation. The simple transformation x -> |x| renders this \n",
      "                         : variable powerful for the use in a Fisher discriminant.\n",
      "                         : \n",
      "                         : \u001b[1m--- Performance tuning via configuration options:\u001b[0m\n",
      "                         : \n",
      "                         : <None>\n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "Fisher                   : Results for Fisher coefficients:\n",
      "                         : -----------------------\n",
      "                         : Variable:  Coefficient:\n",
      "                         : -----------------------\n",
      "                         :   myvar1:       -0.608\n",
      "                         :   myvar2:       -0.177\n",
      "                         :     var3:       -0.358\n",
      "                         :     var4:       +1.423\n",
      "                         : (offset):       -0.210\n",
      "                         : -----------------------\n",
      "                         : Elapsed time for training with 6000 events: 0.00542 sec         \n",
      "Fisher                   : [dataset] : Evaluation of Fisher on training sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.000777 sec       \n",
      "                         : Dataset[dataset] : <CreateMVAPdfs> Separation from histogram (PDF): 0.540 (0.000)\n",
      "                         : Dataset[dataset] : Evaluation of Fisher on training sample\n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_Fisher.weights.xml\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_Fisher.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: BDT for Classification\n",
      "                         : \n",
      "BDT                      : #events: (reweighted) sig: 3000 bkg: 3000\n",
      "                         : #events: (unweighted) sig: 3000 bkg: 3000\n",
      "                         : Training 200 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 6000 events: 5.34 sec         \n",
      "BDT                      : [dataset] : Evaluation of BDT on training sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.0716 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_BDT.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_BDT.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "Factory                  : Train method: MLP for Classification\n",
      "                         : \n",
      "TFHandler_MLP            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:   0.074087    0.20922   [    -1.0000     1.0000 ]\n",
      "                         :   myvar2:  0.0048960    0.27268   [    -1.0000     1.0000 ]\n",
      "                         :     var3:   0.071649    0.22792   [    -1.0000     1.0000 ]\n",
      "                         :     var4:    0.11962    0.23306   [    -1.0000     1.0000 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : Training Network\n",
      "                         : \n",
      "                         : Elapsed time for training with 6000 events: 2.22 sec         \n",
      "MLP                      : [dataset] : Evaluation of MLP on training sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.00677 sec       \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVAClassification_MLP.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVAClassification_MLP.class.C\u001b[0m\n",
      "                         : Write special histos to file: TMVA_ClassificationOutput.root:/dataset/Method_MLP/MLP\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "Likelihood               : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable  : Delta Separation\n",
      "                         : -------------------------------------\n",
      "                         :    1 : var4      : 4.486e-02\n",
      "                         :    2 : myvar2    : -1.565e-03\n",
      "                         :    3 : var3      : -3.184e-03\n",
      "                         :    4 : myvar1    : -1.297e-02\n",
      "                         : -------------------------------------\n",
      "LikelihoodKDE            : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable  : Delta Separation\n",
      "                         : -------------------------------------\n",
      "                         :    1 : var4      : 7.648e-02\n",
      "                         :    2 : myvar2    : -2.045e-03\n",
      "                         :    3 : var3      : -1.390e-02\n",
      "                         :    4 : myvar1    : -2.601e-02\n",
      "                         : -------------------------------------\n",
      "Fisher                   : Ranking result (top variable is best ranked)\n",
      "                         : ---------------------------------\n",
      "                         : Rank : Variable  : Discr. power\n",
      "                         : ---------------------------------\n",
      "                         :    1 : var4      : 1.464e-01\n",
      "                         :    2 : var3      : 7.049e-02\n",
      "                         :    3 : myvar1    : 4.301e-02\n",
      "                         :    4 : myvar2    : 2.898e-03\n",
      "                         : ---------------------------------\n",
      "BDT                      : Ranking result (top variable is best ranked)\n",
      "                         : ----------------------------------------\n",
      "                         : Rank : Variable  : Variable Importance\n",
      "                         : ----------------------------------------\n",
      "                         :    1 : var4      : 3.680e-01\n",
      "                         :    2 : myvar1    : 2.966e-01\n",
      "                         :    3 : myvar2    : 1.843e-01\n",
      "                         :    4 : var3      : 1.510e-01\n",
      "                         : ----------------------------------------\n",
      "MLP                      : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------\n",
      "                         : Rank : Variable  : Importance\n",
      "                         : -------------------------------\n",
      "                         :    1 : var4      : 6.086e+00\n",
      "                         :    2 : myvar1    : 3.171e+00\n",
      "                         :    3 : var3      : 8.099e-01\n",
      "                         :    4 : myvar2    : 5.759e-01\n",
      "                         : -------------------------------\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_Likelihood.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_LikelihoodKDE.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_Fisher.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_BDT.weights.xml\u001b[0m\n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVAClassification_MLP.weights.xml\u001b[0m\n",
      "MLP                      : Building Network. \n",
      "                         : Initializing weights\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test  all methods\n",
    "\n",
    "Here we test all methods using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: Likelihood for Classification performance\n",
      "                         : \n",
      "Likelihood               : [dataset] : Evaluation of Likelihood on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.0123 sec       \n",
      "Factory                  : Test method: LikelihoodKDE for Classification performance\n",
      "                         : \n",
      "LikelihoodKDE            : [dataset] : Evaluation of LikelihoodKDE on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.00858 sec       \n",
      "Factory                  : Test method: Fisher for Classification performance\n",
      "                         : \n",
      "Fisher                   : [dataset] : Evaluation of Fisher on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.000746 sec       \n",
      "                         : Dataset[dataset] : Evaluation of Fisher on testing sample\n",
      "Factory                  : Test method: BDT for Classification performance\n",
      "                         : \n",
      "BDT                      : [dataset] : Evaluation of BDT on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.0588 sec       \n",
      "Factory                  : Test method: MLP for Classification performance\n",
      "                         : \n",
      "MLP                      : [dataset] : Evaluation of MLP on testing sample (6000 events)\n",
      "                         : Elapsed time for evaluation of 6000 events: 0.00968 sec       \n"
     ]
    }
   ],
   "source": [
    "factory.TestAllMethods();  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate  all methods\n",
    "\n",
    "Here we evaluate all methods and compare their performances, computing efficiencies, ROC curves etc.. using both \n",
    "training and tetsing data sets. \n",
    "Several histograms are produced which can be examined with the TMVAGui or directly using the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: Likelihood\n",
      "                         : \n",
      "Likelihood               : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_Likelihood     : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.20474     1.7127   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.053190     1.1047   [    -3.7067     4.0291 ]\n",
      "                         :     var3:    0.15738     1.0532   [    -5.3563     4.6430 ]\n",
      "                         :     var4:    0.42980     1.2189   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: LikelihoodKDE\n",
      "                         : \n",
      "LikelihoodKDE            : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_LikelihoodKDE  : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.20474     1.7127   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.053190     1.1047   [    -3.7067     4.0291 ]\n",
      "                         :     var3:    0.15738     1.0532   [    -5.3563     4.6430 ]\n",
      "                         :     var4:    0.42980     1.2189   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: Fisher\n",
      "                         : \n",
      "Fisher                   : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "                         : Also filling probability and rarity histograms (on request)...\n",
      "TFHandler_Fisher         : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.20474     1.7127   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.053190     1.1047   [    -3.7067     4.0291 ]\n",
      "                         :     var3:    0.15738     1.0532   [    -5.3563     4.6430 ]\n",
      "                         :     var4:    0.42980     1.2189   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: BDT\n",
      "                         : \n",
      "BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_BDT            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.20474     1.7127   [    -9.8605     7.9024 ]\n",
      "                         :   myvar2:  -0.053190     1.1047   [    -3.7067     4.0291 ]\n",
      "                         :     var3:    0.15738     1.0532   [    -5.3563     4.6430 ]\n",
      "                         :     var4:    0.42980     1.2189   [    -6.9675     5.0307 ]\n",
      "                         : -----------------------------------------------------------\n",
      "Factory                  : Evaluate classifier: MLP\n",
      "                         : \n",
      "TFHandler_MLP            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.10099    0.20561   [    -1.1074     1.0251 ]\n",
      "                         :   myvar2: -0.0057788    0.27238   [   -0.90663     1.0008 ]\n",
      "                         :     var3:    0.10689    0.22383   [    -1.0649     1.0602 ]\n",
      "                         :     var4:    0.17360    0.22420   [    -1.1871     1.0199 ]\n",
      "                         : -----------------------------------------------------------\n",
      "MLP                      : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_MLP            : Variable        Mean        RMS   [        Min        Max ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         :   myvar1:    0.10099    0.20561   [    -1.1074     1.0251 ]\n",
      "                         :   myvar2: -0.0057788    0.27238   [   -0.90663     1.0008 ]\n",
      "                         :     var3:    0.10689    0.22383   [    -1.0649     1.0602 ]\n",
      "                         :     var4:    0.17360    0.22420   [    -1.1871     1.0199 ]\n",
      "                         : -----------------------------------------------------------\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       Fisher         : 0.926\n",
      "                         : dataset       MLP            : 0.925\n",
      "                         : dataset       BDT            : 0.914\n",
      "                         : dataset       Likelihood     : 0.756\n",
      "                         : dataset       LikelihoodKDE  : 0.756\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              Fisher         : 0.373 (0.360)       0.780 (0.760)      0.938 (0.930)\n",
      "                         : dataset              MLP            : 0.365 (0.370)       0.783 (0.768)      0.937 (0.928)\n",
      "                         : dataset              BDT            : 0.286 (0.283)       0.748 (0.753)      0.918 (0.914)\n",
      "                         : dataset              Likelihood     : 0.079 (0.085)       0.379 (0.380)      0.689 (0.653)\n",
      "                         : dataset              LikelihoodKDE  : 0.072 (0.080)       0.376 (0.377)      0.691 (0.660)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 6000 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 6000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.EvaluateAllMethods();  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "\n",
    "We plot here the produce ROC curve obtained on evaluating the methods on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//We enable JavaScript visualisation for the plots\n",
    "//%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAHYCAIAAAApvgy/AAAABmJLR0QAAAAAAAD5Q7t/AAAgAElE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\n/wPkMzmu+DSQXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto c1 = factory.GetROCCurve(loader);\n",
    "c1->Draw();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Close outputfile to save all output information (evaluation result of methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFile->Close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT C++",
   "language": "c++",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".C",
   "mimetype": " text/x-c++src",
   "name": "c++"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
