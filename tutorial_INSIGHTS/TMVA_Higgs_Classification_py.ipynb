{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://oproject.org/tiki-download_file.php?fileId=8&display&x=450&y=128\">\n",
    "<img src=\"http://files.oproject.org/tmvalogo.png\" height=\"50%\" width=\"50%\">\n",
    "\n",
    "# TMVA Higgs Classification Example in Python\n",
    "\n",
    "In this example we will still do Higgs classification but we will use together with the native TMVA methods also methods from Keras and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.15/01\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TMVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory\n",
    "\n",
    "Create the Factory class. Later you can choose the methods\n",
    "whose performance you'd like to investigate. \n",
    "\n",
    "The factory is the major TMVA object you have to interact with. Here is the list of parameters you need to pass\n",
    "\n",
    " - The first argument is the base of the name of all the output\n",
    "weightfiles in the directory weight/ that will be created with the \n",
    "method parameters \n",
    "\n",
    " - The second argument is the output file for the training results\n",
    "  \n",
    " - The third argument is a string option defining some general configuration for the TMVA session. For example all TMVA output can be suppressed by removing the \"!\" (not) in front of the \"Silent\" argument in the option string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT.TMVA.Tools.Instance()\n",
    "## For PYMVA methods\n",
    "TMVA.PyMethodBase.PyInitialize();\n",
    "\n",
    "\n",
    "outputFile = ROOT.TFile.Open(\"Higgs_ClassificationOutput.root\", \"RECREATE\")\n",
    "\n",
    "factory = ROOT.TMVA.Factory(\"TMVA_Higgs_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data\n",
    "\n",
    "We define now the input data file and we retrieve the ROOT TTree objects with the signal and background input events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :sig_tree  : Signal Tree                                            *\n",
      "*Entries :    10000 : Total =         1141446 bytes  File  Size =    1000730 *\n",
      "*        :          : Tree compression factor =   1.13                       *\n",
      "******************************************************************************\n",
      "*Br    0 :lepton_pT : lepton_pT/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      30836 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br    1 :lepton_eta : lepton_eta/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40768 bytes  File Size  =      29658 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br    2 :lepton_phi : lepton_phi/F                                          *\n",
      "*Entries :    10000 : Total  Size=      40768 bytes  File Size  =      30676 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br    3 :missing_energy_magnitude : missing_energy_magnitude/F              *\n",
      "*Entries :    10000 : Total  Size=      40866 bytes  File Size  =      31999 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    4 :missing_energy_phi : missing_energy_phi/F                          *\n",
      "*Entries :    10000 : Total  Size=      40824 bytes  File Size  =      31997 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    5 :jet1_pt   : jet1_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40747 bytes  File Size  =      31160 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.03     *\n",
      "*............................................................................*\n",
      "*Br    6 :jet1_eta  : jet1_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      29438 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.09     *\n",
      "*............................................................................*\n",
      "*Br    7 :jet1_phi  : jet1_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      30354 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br    8 :jet1_btag : jet1_btag/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      13830 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   2.31     *\n",
      "*............................................................................*\n",
      "*Br    9 :jet2_pt   : jet2_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40747 bytes  File Size  =      30906 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.04     *\n",
      "*............................................................................*\n",
      "*Br   10 :jet2_eta  : jet2_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      29501 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br   11 :jet2_phi  : jet2_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      30439 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br   12 :jet2_btag : jet2_btag/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      13678 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   2.34     *\n",
      "*............................................................................*\n",
      "*Br   13 :jet3_pt   : jet3_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40747 bytes  File Size  =      30367 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br   14 :jet3_eta  : jet3_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      29687 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br   15 :jet3_phi  : jet3_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      30460 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br   16 :jet3_btag : jet3_btag/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      12542 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   2.55     *\n",
      "*............................................................................*\n",
      "*Br   17 :jet4_pt   : jet4_pt/F                                              *\n",
      "*Entries :    10000 : Total  Size=      40747 bytes  File Size  =      29694 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.08     *\n",
      "*............................................................................*\n",
      "*Br   18 :jet4_eta  : jet4_eta/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      29857 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.07     *\n",
      "*............................................................................*\n",
      "*Br   19 :jet4_phi  : jet4_phi/F                                             *\n",
      "*Entries :    10000 : Total  Size=      40754 bytes  File Size  =      30412 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.05     *\n",
      "*............................................................................*\n",
      "*Br   20 :jet4_btag : jet4_btag/F                                            *\n",
      "*Entries :    10000 : Total  Size=      40761 bytes  File Size  =      11691 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   2.74     *\n",
      "*............................................................................*\n",
      "*Br   21 :m_jj      : m_jj/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40726 bytes  File Size  =      31999 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   22 :m_jjj     : m_jjj/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40733 bytes  File Size  =      31996 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   23 :m_lv      : m_lv/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40726 bytes  File Size  =      31707 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.01     *\n",
      "*............................................................................*\n",
      "*Br   24 :m_jlv     : m_jlv/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40733 bytes  File Size  =      31996 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   25 :m_bb      : m_bb/F                                                 *\n",
      "*Entries :    10000 : Total  Size=      40726 bytes  File Size  =      31999 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   26 :m_wbb     : m_wbb/F                                                *\n",
      "*Entries :    10000 : Total  Size=      40733 bytes  File Size  =      31996 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   27 :m_wwbb    : m_wwbb/F                                               *\n",
      "*Entries :    10000 : Total  Size=      40740 bytes  File Size  =      31997 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "inputFileName = \"Higgs_data.root\"\n",
    "\n",
    "inputFile = ROOT.TFile.Open( inputFileName )\n",
    "\n",
    "# retrieve input trees\n",
    "\n",
    "signalTree     = inputFile.Get(\"sig_tree\")\n",
    "backgroundTree = inputFile.Get(\"bkg_tree\")\n",
    "\n",
    "signalTree.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input data abd variables \n",
    "\n",
    "We add first the signal and background trees in the data loader and then we\n",
    "define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree sig_tree of type Signal with 10000 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree bkg_tree of type Background with 10000 events\n"
     ]
    }
   ],
   "source": [
    "loader = ROOT.TMVA.DataLoader(\"dataset\")\n",
    "\n",
    "### global event weights per tree (see below for setting event-wise weights)\n",
    "signalWeight     = 1.0\n",
    "backgroundWeight = 1.0\n",
    "   \n",
    "### You can add an arbitrary number of signal or background trees\n",
    "loader.AddSignalTree    ( signalTree,     signalWeight     )\n",
    "loader.AddBackgroundTree( backgroundTree, backgroundWeight )\n",
    "\n",
    "## Define input variables \n",
    "\n",
    "loader.AddVariable(\"m_jj\")\n",
    "loader.AddVariable(\"m_jjj\")\n",
    "loader.AddVariable(\"m_lv\")\n",
    "loader.AddVariable(\"m_jlv\")\n",
    "loader.AddVariable(\"m_bb\")\n",
    "loader.AddVariable(\"m_wbb\")\n",
    "loader.AddVariable(\"m_wwbb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset(s)\n",
    "\n",
    "Setup the DataLoader by splitting events in training and test samples. \n",
    "Here we use a random split and a fixed number of training and test events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Apply additional cuts on the signal and background samples (can be different)\n",
    "mycuts = ROOT.TCut(\"\")   ## for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "mycutb = ROOT.TCut(\"\")   ## for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "\n",
    "loader.PrepareTrainingAndTestTree( mycuts, mycutb,\n",
    "                                  \"nTrain_Signal=7000:nTrain_Background=7000:SplitMode=Random:\"\n",
    "                                   \"NormMode=NumEvents:!V\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Booking Methods\n",
    "\n",
    "Here we book the TMVA methods. We book a Likelihood based a BDT and a standard MLP (shallow NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mBDT\u001b[0m\n",
      "                         : \n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 7000\n",
      "                         : Signal     -- testing events             : 3000\n",
      "                         : Signal     -- training and testing events: 10000\n",
      "                         : Background -- training events            : 7000\n",
      "                         : Background -- testing events             : 3000\n",
      "                         : Background -- training and testing events: 10000\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ----------------------------------------------------------------\n",
      "                         :             m_jj   m_jjj    m_lv   m_jlv    m_bb   m_wbb  m_wwbb\n",
      "                         :    m_jj:  +1.000  +0.803  +0.010  +0.120  +0.033  +0.539  +0.533\n",
      "                         :   m_jjj:  +0.803  +1.000  +0.010  +0.112  +0.156  +0.686  +0.658\n",
      "                         :    m_lv:  +0.010  +0.010  +1.000  +0.098  -0.056  +0.004  +0.021\n",
      "                         :   m_jlv:  +0.120  +0.112  +0.098  +1.000  +0.311  +0.558  +0.576\n",
      "                         :    m_bb:  +0.033  +0.156  -0.056  +0.311  +1.000  +0.471  +0.332\n",
      "                         :   m_wbb:  +0.539  +0.686  +0.004  +0.558  +0.471  +1.000  +0.901\n",
      "                         :  m_wwbb:  +0.533  +0.658  +0.021  +0.576  +0.332  +0.901  +1.000\n",
      "                         : ----------------------------------------------------------------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ----------------------------------------------------------------\n",
      "                         :             m_jj   m_jjj    m_lv   m_jlv    m_bb   m_wbb  m_wwbb\n",
      "                         :    m_jj:  +1.000  +0.797  +0.012  +0.169  +0.044  +0.405  +0.426\n",
      "                         :   m_jjj:  +0.797  +1.000  +0.010  +0.198  +0.177  +0.551  +0.533\n",
      "                         :    m_lv:  +0.012  +0.010  +1.000  +0.129  +0.017  +0.031  +0.041\n",
      "                         :   m_jlv:  +0.169  +0.198  +0.129  +1.000  +0.268  +0.604  +0.570\n",
      "                         :    m_bb:  +0.044  +0.177  +0.017  +0.268  +1.000  +0.616  +0.439\n",
      "                         :   m_wbb:  +0.405  +0.551  +0.031  +0.604  +0.616  +1.000  +0.883\n",
      "                         :  m_wwbb:  +0.426  +0.533  +0.041  +0.570  +0.439  +0.883  +1.000\n",
      "                         : ----------------------------------------------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n",
      "Factory                  : Booking method: \u001b[1mMLP\u001b[0m\n",
      "                         : \n",
      "MLP                      : [dataset] : Create Transformation \"N\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n",
      "MLP                      : Building Network. \n",
      "                         : Initializing weights\n"
     ]
    }
   ],
   "source": [
    "## Boosted Decision Trees\n",
    "factory.BookMethod(loader,ROOT.TMVA.Types.kBDT, \"BDT\",\n",
    "                   \"!V:NTrees=200:MinNodeSize=2.5%:MaxDepth=2:BoostType=AdaBoost:AdaBoostBeta=0.5:UseBaggedBoost:\"\n",
    "                   \"BaggedSampleFraction=0.5:SeparationType=GiniIndex:nCuts=20\" )\n",
    "\n",
    "## Multi-Layer Perceptron (Neural Network)\n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kMLP, \"MLP\",\n",
    "                   \"!H:!V:NeuronType=tanh:VarTransform=N:NCycles=100:HiddenLayers=N+5:TestRate=5:!UseRegulator\" );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scikit-learn\n",
    "\n",
    "here we book some scikit learn packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ROOT.TMVA::MethodPyAdaBoost object (\"PyAdaBoost\") at 0x79e7cc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mPyGTB\u001b[0m\n",
      "                         : \n",
      "PyGTB                    : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n",
      "Factory                  : Booking method: \u001b[1mPyRandomForest\u001b[0m\n",
      "                         : \n",
      "PyRandomForest           : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n",
      "Factory                  : Booking method: \u001b[1mPyAdaBoost\u001b[0m\n",
      "                         : \n",
      "PyAdaBoost               : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n"
     ]
    }
   ],
   "source": [
    "factory.BookMethod(loader, ROOT.TMVA.Types.kPyGTB, \"PyGTB\",\"H:!V:VarTransform=G:NEstimators=400:LearningRate=0.1:\"\n",
    "                                                  \"MaxDepth=3\")\n",
    "\n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kPyRandomForest, \"PyRandomForest\",\"!V:VarTransform=G:NEstimators=400:\"\n",
    "                           \"Criterion=gini:MaxFeatures=auto:MaxDepth=6:MinSamplesLeaf=3:MinWeightFractionLeaf=0:\"\n",
    "                            \"Bootstrap=kTRUE\" )\n",
    "      \n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kPyAdaBoost, \"PyAdaBoost\",\"!V:VarTransform=G:NEstimators=400\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booking Deep Neural Network\n",
    "\n",
    "Here we book the new DNN of TMVA. We use the new DL method available in TMVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define DNN layout\n",
    "\n",
    "we need to define (note the use of the character | as  separator of  input parameters) \n",
    "\n",
    "- input layout :   this defines the input data format for the DNN as  input depth | height | width. \n",
    "   In case of a dense layer as first layer the input layout should be  1 | 1 | number of input variables (features)\n",
    "- batch layout  : this defines how are the input batch. It is related to input layout but not the same. \n",
    "   If the first layer is dense it should be 1 | batch size ! number of variables (fetures)\n",
    "                 \n",
    "- layout string defining the architecture. The syntax is  \n",
    "   - layer type (e.g. DENSE, CONV, RNN)\n",
    "   - layer parameters (e.g. number of units)\n",
    "   - activation function (e.g  TANH, RELU,...)\n",
    "   \n",
    "     the different layers are separated by the \",\" \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputLayoutString = \"InputLayout=1|1|7\"; \n",
    "batchLayoutString= \"BatchLayout=1|32|7\";\n",
    "layoutString = (\"Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\")                                                                                                                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define Trainining Strategy\n",
    "\n",
    "We define here the different training strategy for the DNN. One can concatenate different training strategy changing parameters like: \n",
    " - Optimizer\n",
    " - Learning rate\n",
    " - Momentum (valid for SGD and RMSPROP)\n",
    " - Regularization and Weight Decay \n",
    " - Dropout \n",
    " - Max number of epochs \n",
    " - Convergence steps. if the test error will not decrease after that value the training will stop\n",
    " - Batch size (This value must be the same specified in the input layout)\n",
    " - Test Repetitions (the interval when the test error will be computed) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training strategies \n",
    "## one can catenate several training strategies\n",
    "\n",
    "training1  = \"Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,\"\n",
    "training1 += \"DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1\"\n",
    " \n",
    "# we add regularization in the second phase\n",
    "training2  = \"Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=L2,WeightDecay=1e-4,\"\n",
    "training2 += \"DropConfig=0.0+0.0+0.0+0,MaxEpochs=20,ConvergenceSteps=10,BatchSize=1000,TestRepetitions=1\"\n",
    "     \n",
    "            \n",
    "\n",
    "trainingStrategyString = \"TrainingStrategy=\" + training1 ## + training2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define general options and book method\n",
    "\n",
    "We define the general DNN options such as \n",
    "\n",
    "- Type of Loss function (e.g. cross entropy)\n",
    "- Weight Initizalization (e.g XAVIER, XAVIERUNIFORM, NORMAL )\n",
    "- Variable Transformation\n",
    "- Type of Architecture (e.g. CPU, GPU, Standard)\n",
    "\n",
    "We add then also all the other options defined before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Options.                                                                                                                                                                \n",
    "dnnOptions = \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIER::Architecture=CPU\"\n",
    "\n",
    "dnnOptions +=  \":\" + inputLayoutString\n",
    "dnnOptions +=  \":\" + batchLayoutString\n",
    "dnnOptions +=  \":\" + layoutString\n",
    "dnnOptions +=  \":\" + trainingStrategyString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ROOT.TMVA::MethodDL object (\"DL_CPU\") at 0x724b120>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mDL_CPU\u001b[0m\n",
      "                         : \n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIER::Architecture=CPU:InputLayout=1|1|7:BatchLayout=1|32|7:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     <none>\n",
      "                         : - Default:\n",
      "                         :     Boost_num: \"0\" [Number of times the classifier will be boosted]\n",
      "                         : Parsing option string: \n",
      "                         : ... \"!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIER::Architecture=CPU:InputLayout=1|1|7:BatchLayout=1|32|7:Layout=DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR:TrainingStrategy=Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1\"\n",
      "                         : The following options are set:\n",
      "                         : - By User:\n",
      "                         :     V: \"True\" [Verbose output (short form of \"VerbosityLevel\" below - overrides the latter one)]\n",
      "                         :     VarTransform: \"G\" [List of variable transformations performed before training, e.g., \"D_Background,P_Signal,G,N_AllClasses\" for: \"Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)\"]\n",
      "                         :     H: \"False\" [Print method-specific help message]\n",
      "                         :     InputLayout: \"1|1|7\" [The Layout of the input]\n",
      "                         :     BatchLayout: \"1|32|7\" [The Layout of the batch]\n",
      "                         :     Layout: \"DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|64|TANH,DENSE|1|LINEAR\" [Layout of the network.]\n",
      "                         :     ErrorStrategy: \"CROSSENTROPY\" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]\n",
      "                         :     WeightInitialization: \"XAVIER\" [Weight initialization strategy]\n",
      "                         :     Architecture: \"CPU\" [Which architecture to perform the training on.]\n",
      "                         :     TrainingStrategy: \"Optimizer=ADAM,LearningRate=1e-3,Momentum=0.,Regularization=None,WeightDecay=1e-4,DropConfig=0.+0.+0.+0.,MaxEpochs=30,ConvergenceSteps=10,BatchSize=32,TestRepetitions=1\" [Defines the training strategies.]\n",
      "                         : - Default:\n",
      "                         :     VerbosityLevel: \"Default\" [Verbosity level]\n",
      "                         :     CreateMVAPdfs: \"False\" [Create PDFs for classifier outputs (signal and background)]\n",
      "                         :     IgnoreNegWeightsInTraining: \"False\" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]\n",
      "                         :     RandomSeed: \"0\" [Random seed used for weight initialization and batch shuffling]\n",
      "DL_CPU                   : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n",
      "                         : Will use now the CPU architecture !\n"
     ]
    }
   ],
   "source": [
    "#we can now book the method\n",
    "              \n",
    "factory.BookMethod(loader, ROOT.TMVA.Types.kDL, \"DL_CPU\", dnnOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to use tensorflow backend\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "#from keras.initializers import TruncatedNormal\n",
    "#from keras import initializations\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "#from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 8,962\n",
      "Trainable params: 8,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-20 11:32:55.772660: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, kernel_initializer='glorot_normal', activation='tanh', input_dim=7))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, kernel_initializer='glorot_normal', activation='tanh'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, kernel_initializer='glorot_normal', activation='tanh'))\n",
    "model.add(Dense(2, kernel_initializer='glorot_uniform', activation='softmax'))\n",
    "\n",
    "# Set loss and optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['categorical_accuracy',])\n",
    "\n",
    "# Store model to file\n",
    "model.save('model_dense.h5')\n",
    "\n",
    "# Print summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ROOT.TMVA::MethodPyKeras object (\"Keras_Dense\") at 0x9b942a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mKeras_Dense\u001b[0m\n",
      "                         : \n",
      "Keras_Dense              : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_jj' <---> Output : variable 'm_jj'\n",
      "                         : Input : variable 'm_jjj' <---> Output : variable 'm_jjj'\n",
      "                         : Input : variable 'm_lv' <---> Output : variable 'm_lv'\n",
      "                         : Input : variable 'm_jlv' <---> Output : variable 'm_jlv'\n",
      "                         : Input : variable 'm_bb' <---> Output : variable 'm_bb'\n",
      "                         : Input : variable 'm_wbb' <---> Output : variable 'm_wbb'\n",
      "                         : Input : variable 'm_wwbb' <---> Output : variable 'm_wwbb'\n",
      "                         : Load model from file: model_dense.h5\n"
     ]
    }
   ],
   "source": [
    "factory.BookMethod(loader, ROOT.TMVA.Types.kPyKeras, 'Keras_Dense',\n",
    "        'H:!V:VarTransform=G:FilenameModel=model_dense.h5:'+\\\n",
    "        'NumEpochs=30:BatchSize=32:TriesEarlyStopping=10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.TrainAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test  all methods\n",
    "\n",
    "Here we test all methods using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.TestAllMethods();   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate all methods\n",
    "\n",
    "Here we evaluate all methods and compare their performances, computing efficiencies, ROC curves etc.. using both training and tetsing data sets. Several histograms are produced which can be examined with the TMVAGui or directly using the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.EvaluateAllMethods();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "We enable JavaScript visualisation for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = factory.GetROCCurve(loader);\n",
    "c1.Draw();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Close outputfile to save all output information (evaluation result of methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##outputFile.Close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
